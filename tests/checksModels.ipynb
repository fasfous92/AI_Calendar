{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalenderAI using HugginFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once was a Python so bright,\n",
      "Its syntax was easy to write.\n",
      "It handled with flair,\n",
      "Modules beyond compare,\n",
      "And its libraries shone with great light.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(\"meta-llama/Llama-3.2-3B-Instruct\", token=os.getenv(\"Hugging_Face_Browser_API_KEY\"))\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"ollama\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You're a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a limerick about the Python programming language.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\"meta-llama/Llama-3.2-3B-Instruct\", token=os.getenv(\"Hugging_Face_Browser_API_KEY\"))\n",
    "model=\"ollama\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Router LLM call: Determine the type of calendar request',\n",
       " 'properties': {'request_type': {'description': 'Type of calendar request being made',\n",
       "   'enum': ['new_event', 'modify_event', 'other'],\n",
       "   'title': 'Request Type',\n",
       "   'type': 'string'},\n",
       "  'confidence_score': {'description': 'Confidence score number between 0 and 1',\n",
       "   'maximum': 1.0,\n",
       "   'minimum': 0.0,\n",
       "   'title': 'Confidence Score',\n",
       "   'type': 'number'},\n",
       "  'description': {'description': 'Cleaned description of the request',\n",
       "   'title': 'Description',\n",
       "   'type': 'string'}},\n",
       " 'required': ['request_type', 'confidence_score', 'description'],\n",
       " 'title': 'CalendarRequestType',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalendarRequestType.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Define the data models for routing and responses\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "class CalendarRequestType(BaseModel):\n",
    "    \"\"\"Router LLM call: Determine the type of calendar request\"\"\"\n",
    "\n",
    "    request_type: Literal[\"new_event\", \"modify_event\", \"other\"] = Field(\n",
    "        description=\"Type of calendar request being made\"\n",
    "    )\n",
    "    confidence_score: float = Field(description=\"Confidence score is a number between 0.0 and 1.0\")\n",
    "                     \n",
    "    description: str = Field(description=\"Cleaned description of the request\")\n",
    "    \n",
    " \n",
    "\n",
    "class NewEventDetails(BaseModel):\n",
    "    \"\"\"Details for creating a new event\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the event\")\n",
    "    date: str = Field(description=\"Date and time of the event (ISO 8601)\")\n",
    "    duration_minutes: int = Field(description=\"Duration in minutes\")\n",
    "    participants: list[str] = Field(description=\"List of participants\")\n",
    "\n",
    "\n",
    "class Change(BaseModel):\n",
    "    \"\"\"Details for changing an existing event\"\"\"\n",
    "\n",
    "    field: str = Field(description=\"Field to change\")\n",
    "    new_value: str = Field(description=\"New value for the field\")\n",
    "\n",
    "\n",
    "class ModifyEventDetails(BaseModel):\n",
    "    \"\"\"Details for modifying an existing event\"\"\"\n",
    "\n",
    "    event_identifier: str = Field(\n",
    "        description=\"Description to identify the existing event\"\n",
    "    )\n",
    "    changes: list[Change] = Field(description=\"List of changes to make\")\n",
    "    participants_to_add: list[str] = Field(description=\"New participants to add\")\n",
    "    participants_to_remove: list[str] = Field(description=\"Participants to remove\")\n",
    "\n",
    "\n",
    "class CalendarResponse(BaseModel):\n",
    "    \"\"\"Final response format\"\"\"\n",
    "\n",
    "    success: bool = Field(description=\"Whether the operation was successful\")\n",
    "    message: str = Field(description=\"User-friendly response message\")\n",
    "    calendar_link: Optional[str] = Field(description=\"Calendar link if applicable\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Define the routing and processing functions\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def route_calendar_request(user_input: str) -> CalendarRequestType:\n",
    "    \"\"\"Router LLM call to determine the type of calendar request\"\"\"\n",
    "    logger.info(\"Routing calendar request\")\n",
    "    \n",
    "    #-----add the schema to the response format   \n",
    "    response_format = {\n",
    "    \"type\": \"json\",\n",
    "    \"value\": CalendarRequestType.model_json_schema()  # Add the generated schema as the response format\n",
    "    }\n",
    "    \n",
    "    #-----write the messages to pass to the model\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Determine if this is a request to create a new calendar event or modify an existing one.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages= messages,\n",
    "        response_format=response_format\n",
    "    )\n",
    "    \n",
    "    result = completion.choices[0].message.content\n",
    "    result=json.loads(result)\n",
    "    calednType=CalendarRequestType(**result)\n",
    "    #.parsed\n",
    "    # result_dict = json.loads(result)\n",
    "    # print(\"result_dict\", result_dict)\n",
    "    # data=json.loads(result_dict)\n",
    "    # print('data', data)\n",
    "    # test = CalendarRequestType(**data)\n",
    "    logger.info(\n",
    "        f\"Request routed as: {calednType}\",\n",
    "       # f\"Request routed as: {test.request_type} with confidence: {test.confidence_score}\"\n",
    "    )\n",
    "    return calednType\n",
    "\n",
    "\n",
    "def handle_new_event(description: str) -> CalendarResponse:\n",
    "    \"\"\"Process a new event request\"\"\"\n",
    "    logger.info(\"Processing new event request\")\n",
    "\n",
    "    # Get event details\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract details for creating a new calendar event.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        response_format=NewEventDetails,\n",
    "    )\n",
    "    details = completion.choices[0].message.parsed\n",
    "\n",
    "    logger.info(f\"New event: {details.model_dump_json(indent=2)}\")\n",
    "\n",
    "    # Generate response\n",
    "    return CalendarResponse(\n",
    "        success=True,\n",
    "        message=f\"Created new event '{details.name}' for {details.date} with {', '.join(details.participants)}\",\n",
    "        calendar_link=f\"calendar://new?event={details.name}\",\n",
    "    )\n",
    "\n",
    "\n",
    "def handle_modify_event(description: str) -> CalendarResponse:\n",
    "    \"\"\"Process an event modification request\"\"\"\n",
    "    logger.info(\"Processing event modification request\")\n",
    "\n",
    "    # Get modification details\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract details for modifying an existing calendar event.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        response_format=ModifyEventDetails,\n",
    "    )\n",
    "    details = completion.choices[0].message.parsed\n",
    "\n",
    "    logger.info(f\"Modified event: {details.model_dump_json(indent=2)}\")\n",
    "\n",
    "    # Generate response\n",
    "    return CalendarResponse(\n",
    "        success=True,\n",
    "        message=f\"Modified event '{details.event_identifier}' with the requested changes\",\n",
    "        calendar_link=f\"calendar://modify?event={details.event_identifier}\",\n",
    "    )\n",
    "\n",
    "\n",
    "def process_calendar_request(user_input: str) -> Optional[CalendarResponse]:\n",
    "    \"\"\"Main function implementing the routing workflow\"\"\"\n",
    "    logger.info(\"Processing calendar request\")\n",
    "\n",
    "    # Route the request\n",
    "    route_result = route_calendar_request(user_input)\n",
    "\n",
    "    # # Check confidence threshold\n",
    "    # if route_result.confidence_score < 0.7:\n",
    "    #     logger.warning(f\"Low confidence score: {route_result.confidence_score}\")\n",
    "    #     return None\n",
    "\n",
    "    # # Route to appropriate handler\n",
    "    # if route_result.request_type == \"new_event\":\n",
    "    #     return handle_new_event(route_result.description)\n",
    "    # elif route_result.request_type == \"modify_event\":\n",
    "    #     return handle_modify_event(route_result.description)\n",
    "    # else:\n",
    "    #     logger.warning(\"Request type not supported\")\n",
    "    #     return None\n",
    "    return route_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 11:03:16 - INFO - Processing calendar request\n",
      "2025-02-14 11:03:16 - INFO - Routing calendar request\n",
      "2025-02-14 11:03:17 - INFO - Request routed as: request_type='new_event' confidence_score=96.0 description='meeting with John and Jane on Monday at 10 AM'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: request_type='new_event' confidence_score=96.0 description='meeting with John and Jane on Monday at 10 AM'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Test with new event\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "new_event_input = \"let's schedule a meeting with John and Jane on Monday at 10 AM\"\n",
    "result = process_calendar_request(new_event_input)\n",
    "if result:\n",
    "    print(f\"Response: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Router LLM call: Determine the type of calendar request',\n",
       " 'properties': {'request_type': {'description': 'Type of calendar request being made',\n",
       "   'enum': ['new_event', 'modify_event', 'other'],\n",
       "   'title': 'Request Type',\n",
       "   'type': 'string'},\n",
       "  'confidence_score': {'description': 'Confidence score between 0 and 1',\n",
       "   'title': 'Confidence Score',\n",
       "   'type': 'number'},\n",
       "  'description': {'description': 'Cleaned description of the request',\n",
       "   'title': 'Description',\n",
       "   'type': 'string'}},\n",
       " 'required': ['request_type', 'confidence_score', 'description'],\n",
       " 'title': 'CalendarRequestType',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalendarRequestType.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35516/3517091682.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  CalendarRequestType.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'Router LLM call: Determine the type of calendar request',\n",
       " 'properties': {'request_type': {'description': 'Type of calendar request being made',\n",
       "   'enum': ['new_event', 'modify_event', 'other'],\n",
       "   'title': 'Request Type',\n",
       "   'type': 'string'},\n",
       "  'confidence_score': {'description': 'Confidence score between 0 and 1',\n",
       "   'title': 'Confidence Score',\n",
       "   'type': 'number'},\n",
       "  'description': {'description': 'Cleaned description of the request',\n",
       "   'title': 'Description',\n",
       "   'type': 'string'}},\n",
       " 'required': ['request_type', 'confidence_score', 'description'],\n",
       " 'title': 'CalendarRequestType',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalendarRequestType.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 4: Test with modify event\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "modify_event_input = (\n",
    "    \"Can you move the team meeting with Alice and Bob to Wednesday at 3pm instead?\"\n",
    ")\n",
    "result = process_calendar_request(modify_event_input)\n",
    "if result:\n",
    "    print(f\"Response: {result.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 5: Test with invalid request\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "invalid_input = \"What's the weather like today?\"\n",
    "result = process_calendar_request(invalid_input)\n",
    "if not result:\n",
    "    print(\"Request not recognized as a calendar operation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='The', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' capital', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' of', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' France', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' is', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' **', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='Paris', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='**.', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' ', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='ðŸ‡«', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='ðŸ‡·', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content=' ', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='\\n', tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n",
      "ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role='assistant', content='', tool_calls=None), index=0, finish_reason='stop', logprobs=None)], created=1739523105, id='', model='google/gemma-2-2b-it', system_fingerprint='3.0.1-sha-bb9095a', usage=None)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=os.getenv(\"Hugging_Face_Browser_API_KEY\"))\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"What is the capital of France?\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"google/gemma-2-2b-it\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"location\":\"park\", \"activity\":\"bike ride\", \"animals_seen\": 3, \"animals\": [\"puppy\", \"cat\", \"raccoon\"] }'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(\"meta-llama/Llama-3.2-3B-Instruct\",api_key=os.getenv(\"Hugging_Face_Browser_API_KEY\"))\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I saw a puppy a cat and a raccoon during my bike ride in the park. What did I saw and when?\",\n",
    "    },\n",
    "]\n",
    "response_format = {\n",
    "    \"type\": \"json\",\n",
    "    \"value\": {\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\"},\n",
    "            \"activity\": {\"type\": \"string\"},\n",
    "            \"animals_seen\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 5},\n",
    "            \"animals\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"location\", \"activity\", \"animals_seen\", \"animals\"],\n",
    "    },\n",
    "}\n",
    "response = client.chat_completion(\n",
    "    messages=messages,\n",
    "    response_format=response_format,\n",
    "    max_tokens=500,\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
